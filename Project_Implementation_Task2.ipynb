{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_Implementation_Task2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achaudhury7378/IE-643-Implementation/blob/main/Project_Implementation_Task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otDoNfG8DZG_"
      },
      "source": [
        "# Importing The Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ylt9UBYhlb_f"
      },
      "source": [
        "import argparse\n",
        "import copy\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision.utils as vutils\n",
        "import seaborn as sns\n",
        "import torch.nn.init as init\n",
        "import pickle\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALkl7L0-n24F"
      },
      "source": [
        "#ANCHOR Print table of zeros and non-zeros count\n",
        "def print_nonzeros(model):\n",
        "    nonzero = total = 0\n",
        "    for name, p in model.named_parameters():\n",
        "        tensor = p.data.cpu().numpy()\n",
        "        nz_count = np.count_nonzero(tensor)\n",
        "        total_params = np.prod(tensor.shape)\n",
        "        nonzero += nz_count\n",
        "        total += total_params\n",
        "        print(f'{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | total_pruned = {total_params - nz_count :7} | shape = {tensor.shape}')\n",
        "    print(f'alive: {nonzero}, pruned : {total - nonzero}, total: {total}, Compression rate : {total/nonzero:10.2f}x  ({100 * (total-nonzero) / total:6.2f}% pruned)')\n",
        "    return (round((nonzero/total)*100,1))\n",
        "\n",
        "def original_initialization(mask_temp, initial_state_dict):\n",
        "    global model\n",
        "    \n",
        "    step = 0\n",
        "    for name, param in model.named_parameters(): \n",
        "        if \"weight\" in name: \n",
        "            weight_dev = param.device\n",
        "            param.data = torch.from_numpy(mask_temp[step] * initial_state_dict[name].cpu().numpy()).to(weight_dev)\n",
        "            step = step + 1\n",
        "        if \"bias\" in name:\n",
        "            param.data = initial_state_dict[name]\n",
        "    step = 0\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "#ANCHOR Checks of the directory exist and if not, creates a new directory\n",
        "def checkdir(directory):\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "\n",
        "#FIXME \n",
        "def plot_train_test_stats(stats,\n",
        "                          epoch_num,\n",
        "                          key1='train',\n",
        "                          key2='test',\n",
        "                          key1_label=None,\n",
        "                          key2_label=None,\n",
        "                          xlabel=None,\n",
        "                          ylabel=None,\n",
        "                          title=None,\n",
        "                          yscale=None,\n",
        "                          ylim_bottom=None,\n",
        "                          ylim_top=None,\n",
        "                          savefig=None,\n",
        "                          sns_style='darkgrid'\n",
        "                          ):\n",
        "\n",
        "    assert len(stats[key1]) == epoch_num, \"len(stats['{}'])({}) != epoch_num({})\".format(key1, len(stats[key1]), epoch_num)\n",
        "    assert len(stats[key2]) == epoch_num, \"len(stats['{}'])({}) != epoch_num({})\".format(key2, len(stats[key2]), epoch_num)\n",
        "\n",
        "    plt.clf()\n",
        "    sns.set_style(sns_style)\n",
        "    x_ticks = np.arange(epoch_num)\n",
        "\n",
        "    plt.plot(x_ticks, stats[key1], label=key1_label)\n",
        "    plt.plot(x_ticks, stats[key2], label=key2_label)\n",
        "\n",
        "    if xlabel is not None:\n",
        "        plt.xlabel(xlabel)\n",
        "    if ylabel is not None:\n",
        "        plt.ylabel(ylabel)\n",
        "\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "\n",
        "    if yscale is not None:\n",
        "        plt.yscale(yscale)\n",
        "\n",
        "    if ylim_bottom is not None:\n",
        "        plt.ylim(bottom=ylim_bottom)\n",
        "    if ylim_top is not None:\n",
        "        plt.ylim(top=ylim_top)\n",
        "\n",
        "    plt.legend(bbox_to_anchor=(1.04,0.5), loc=\"center left\", borderaxespad=0, fancybox=True)\n",
        "\n",
        "    if savefig is not None:\n",
        "        plt.savefig(savefig, bbox_inches='tight')\n",
        "    else:\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq3owQ4n_xaa"
      },
      "source": [
        "# Defining FC1 architecture with 5 neurons in last layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1M2M6GJ_rIF"
      },
      "source": [
        "class fc1(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes = 10):\n",
        "        super(fc1, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(28*28, 300),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(300, 100),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(100, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RWoG7B_Z3Ui"
      },
      "source": [
        "# Defining the Training and Testing Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBP1efHtZ21j"
      },
      "source": [
        "#######################################   \n",
        "# Function for Training\n",
        "#######################################\n",
        "def train(model, train_loader, optimizer, criterion):\n",
        "    EPS = 1e-6\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.train()\n",
        "    for batch_idx, (imgs, targets) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()         ## Clear out the gradients from the last step (otherwise weâ€™d just accumulate the gradients from all loss.backward() calls)\n",
        "        imgs, targets = imgs.to(device), targets.to(device)\n",
        "        output = model(imgs)\n",
        "        train_loss = criterion(output, targets)\n",
        "        train_loss.backward()         ## computes the derivative of the loss w.r.t. the parameters using backpropagation.\n",
        "\n",
        "    ## Freezing Pruned weights by making their gradients Zero\n",
        "        for name, p in model.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                tensor = p.data.cpu().numpy()\n",
        "                grad_tensor = p.grad.data.cpu().numpy()\n",
        "                grad_tensor = np.where(tensor < EPS, 0, grad_tensor)\n",
        "                p.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
        "        optimizer.step()              ##  causes the optimizer to take a step based on the gradients of the parameters\n",
        "    return train_loss.item()\n",
        "\n",
        "#######################################\n",
        "# Function for Testing\n",
        "#######################################\n",
        "def test(model, test_loader, criterion):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()   ## sum up batch loss\n",
        "            pred = output.data.max(1, keepdim=True)[1]                        ## get the index of the max log-probability\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW1UPSoHaPHx"
      },
      "source": [
        "# Defining the Prune_by_percentile module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfH3AQ-BaONL"
      },
      "source": [
        "#######################################\n",
        "# Prune by Percentile module\n",
        "#######################################\n",
        "def prune_by_percentile(percent, resample=False, reinit=False,**kwargs):\n",
        "        global step\n",
        "        global mask\n",
        "        global model\n",
        "\n",
        "        step = 0\n",
        "        \n",
        "        for name, param in model.named_parameters():\n",
        "\n",
        "        ## Note: We do not prune bias term\n",
        "            if 'weight' in name:\n",
        "                tensor = param.data.cpu().numpy()\n",
        "                alive = tensor[np.nonzero(tensor)]         ## flattened array of nonzero values\n",
        "                percentile_value = np.percentile(abs(alive), percent)   ## Calculating percentile value\n",
        "\n",
        "            ## Convert Tensors to numpy and calculate\n",
        "                weight_dev = param.device\n",
        "                new_mask = np.where(abs(tensor) < percentile_value, 0, mask[step])\n",
        "                \n",
        "            ## Apply new weight and mask\n",
        "                param.data = torch.from_numpy(tensor * new_mask).to(weight_dev)\n",
        "                mask[step] = new_mask\n",
        "                step += 1\n",
        "        step = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8lI3FsZakox"
      },
      "source": [
        "# Defining the function for Weight Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOWRk4Vlaebr"
      },
      "source": [
        "#######################################\n",
        "# Function for Initialization\n",
        "#######################################\n",
        "def weight_init(m):\n",
        "    '''\n",
        "    Usage:\n",
        "        model = Model()\n",
        "        model.apply(weight_init)\n",
        "    '''\n",
        "    if isinstance(m, nn.Conv1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.Conv2d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.Conv3d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose2d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose3d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.BatchNorm1d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm3d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.LSTM):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.LSTMCell):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.GRU):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.GRUCell):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4vI4xVa_sLi"
      },
      "source": [
        "# Main procedure: Training over classes 0-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c55FXSWu6ghs",
        "outputId": "6e5be2da-35a9-4dd6-832c-2f812cc2e4a4"
      },
      "source": [
        "\n",
        "## Main\n",
        "writer = SummaryWriter()\n",
        "\n",
        "def main(args, ITE=0):\n",
        "    \n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    reinit = True if args.prune_type==\"reinit\" else False\n",
        "    \n",
        "    ##########################\n",
        "    ## Data Loader\n",
        "    ##########################\n",
        "    transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
        "    \n",
        "    ##########################################################################\n",
        "    ## Subsetting the MNIST data to select only Class 0,1,2,3 and 4 labels\n",
        "    ##########################################################################\n",
        "    if args.dataset == \"mnist\":\n",
        "        traindataset = datasets.MNIST('../data', train = True, download = True, transform = transform)\n",
        "        testdataset = datasets.MNIST('../data', train=False, transform=transform)\n",
        "    ## Extracting index for classes 0,1,2,3,4\n",
        "        idx = (traindataset.targets==0) | (traindataset.targets==1) | (traindataset.targets==2) | (traindataset.targets==3) | (traindataset.targets==4)\n",
        "        idx2 = (testdataset.targets==0) | (testdataset.targets==1) | (testdataset.targets==2) | (testdataset.targets==3) | (testdataset.targets==4) \n",
        "    ## Loading the train data corresponding to reqd classes\n",
        "        traindataset.targets = traindataset.targets[idx]\n",
        "        traindataset.data = traindataset.data[idx]\n",
        "    \n",
        "    ## Loading the test data corresponding to reqd classes\n",
        "        testdataset.targets = testdataset.targets[idx2]\n",
        "        testdataset.data = testdataset.data[idx2]\n",
        "\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(traindataset, batch_size = args.batch_size, shuffle = True, num_workers = 0, drop_last = False)\n",
        "    test_loader = torch.utils.data.DataLoader(testdataset, batch_size = args.batch_size, shuffle = False, num_workers = 0, drop_last = True)\n",
        "    \n",
        "    ##################################################\n",
        "    # Importing Network Architecture\n",
        "    ##################################################\n",
        "    global model\n",
        "    if args.arch_type == \"fc1\":\n",
        "       model = fc1().to(device)\n",
        "    elif args.arch_type == \"lenet5\":\n",
        "        model = LeNet5().to(device)\n",
        "\n",
        "    ####################################\n",
        "    # Weight Initialization\n",
        "    ####################################\n",
        "    model.apply(weight_init)\n",
        "\n",
        "    ###########################################\n",
        "    ## Copying and Saving Initial State\n",
        "    ###########################################\n",
        "    initial_state_dict = copy.deepcopy(model.state_dict())\n",
        "    checkdir(f\"{os.getcwd()}/saves/{args.arch_type}/{args.dataset}/\")\n",
        "    torch.save(model, f\"{os.getcwd()}/saves/{args.arch_type}/{args.dataset}/initial_state_dict_{args.prune_type}.pth.tar\")\n",
        "\n",
        "    ############################\n",
        "    ## Making Initial Mask\n",
        "    ############################\n",
        "    make_mask(model)\n",
        "\n",
        "    ###########################\n",
        "    ## Optimizer and Loss\n",
        "    ###########################\n",
        "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4)\n",
        "    criterion = nn.CrossEntropyLoss()         ## Default was F.nll_loss\n",
        "    \n",
        "    #######################\n",
        "    ## Layer Looper\n",
        "    #######################\n",
        "    for name, param in model.named_parameters():\n",
        "        print(name, param.size())\n",
        "\n",
        "    #########################################################\n",
        "    ## Pruning\n",
        "    ## NOTE: First Pruning Iteration is of No Compression\n",
        "    ##########################################################\n",
        "    best_accuracy = 0                     ## Variable for storing Best accuracy observed in each prune iteration\n",
        "    ITERATION = args.prune_iterations     ## No. of Prune iterations as put in argument while calling\n",
        "    comp = np.zeros(ITERATION,float)      ## Array for storing % weights left after pruning in each prune iteration\n",
        "    bestacc = np.zeros(ITERATION,float)   ## Array for storing Best accuracy in each prune iteration \n",
        "    step = 0\n",
        "    all_loss = np.zeros(args.end_iter,float)      ## Array for storing loss in each training iteration\n",
        "    all_accuracy = np.zeros(args.end_iter,float)  ## Array for storing accuracy in each training iteration\n",
        "\n",
        "\n",
        "    for _ite in range(args.start_iter, ITERATION):      ## Iterating over no. of prune iterations\n",
        "        if not _ite == 0:      ## So that in the very first iteration, 100% of the weights remain\n",
        "            prune_by_percentile(args.prune_percent, resample = resample, reinit = reinit)\n",
        "            \n",
        "            if reinit:                     ## If weights are set to re-initialization\n",
        "                model.apply(weight_init)   ## Weight initialized using \"weight_init\" fn.\n",
        "                step = 0\n",
        "                for name, param in model.named_parameters():\n",
        "                    if 'weight' in name:\n",
        "                        weight_dev = param.device\n",
        "                        param.data = torch.from_numpy(param.data.cpu().numpy() * mask[step]).to(weight_dev)   ## Applying the mask over the set of parameters\n",
        "                        step = step + 1\n",
        "                step = 0\n",
        "            \n",
        "            else:                       ## If weights are NOT set to re-initialization\n",
        "                original_initialization(mask, initial_state_dict)      ## Applying mask over set of parameters set of original initialization\n",
        "            \n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
        "        \n",
        "        print(\"\\n\")\n",
        "        print(f\" \\n--- Pruning Level [{ITE}:{_ite}/{ITERATION}]: ---\")\n",
        "        \n",
        "        #############################################\n",
        "        ## Print the table of Nonzeros in each layer\n",
        "        #############################################\n",
        "        comp1 = print_nonzeros(model)\n",
        "        comp[_ite] = comp1\n",
        "        pbar = tqdm(range(args.end_iter))\n",
        "\n",
        "        for iter_ in pbar:     ## Iterating over training iterations in each prune iteration\n",
        "            ################################\n",
        "            ## Frequency for Testing\n",
        "            ################################\n",
        "            if iter_ % args.valid_freq == 0:\n",
        "                accuracy = test(model, test_loader, criterion)\n",
        "\n",
        "                ###################\n",
        "                ## Save Weights\n",
        "                ###################\n",
        "                if accuracy > best_accuracy:\n",
        "                    best_accuracy = accuracy\n",
        "                    checkdir(f\"{os.getcwd()}/saves/{args.arch_type}/{args.dataset}/\")\n",
        "                    torch.save(model,f\"{os.getcwd()}/saves/{args.arch_type}/{args.dataset}/{_ite}_model_{args.prune_type}.pth.tar\") \n",
        "            \n",
        "            ###################\n",
        "            ## Training\n",
        "            ###################\n",
        "            loss = train(model, train_loader, optimizer, criterion)\n",
        "            all_loss[iter_] = loss\n",
        "            all_accuracy[iter_] = accuracy\n",
        "            # print(f\"\\nTrain epoch: {iter_} | All_accuracy: {all_accuracy} |  accuracy at that epoch: {accuracy}\")\n",
        "            # print(f\"\\nTrain epoch: {iter_} | All_loss: {all_loss} | accuracy at that epoch: {loss}\")\n",
        "\n",
        "            ###############################################\n",
        "            # Frequency for Printing Accuracy and Loss\n",
        "            ###############################################\n",
        "            if iter_ % args.print_freq == 0:\n",
        "                pbar.set_description(\n",
        "                    f'Train Epoch: {iter_}/{args.end_iter} Loss: {loss:.6f} Accuracy: {accuracy:.2f}% Best Accuracy: {best_accuracy:.2f}%')       \n",
        "\n",
        "        writer.add_scalar('Accuracy/test', best_accuracy, comp1)\n",
        "        bestacc[_ite] = best_accuracy    ## Storing the Best Accuracies in each pruning iteration\n",
        "\n",
        "        ########################################################################################################################################################################################################\n",
        "        ## Plotting Loss (Training), Accuracy (Testing), Iteration Curve\n",
        "        ## NOTE: Loss is computed for every iteration while Accuracy is computed only for every {args.valid_freq} iterations. Therefore Accuracy saved is constant during the uncomputed iterations.\n",
        "        ## NOTE: Normalized the accuracy to [0,100] for ease of plotting.\n",
        "        ########################################################################################################################################################################################################\n",
        "        plt.plot(np.arange(1,(args.end_iter)+1), 100*(all_loss - np.min(all_loss))/np.ptp(all_loss).astype(float), c=\"blue\", label=\"Loss\") \n",
        "        plt.plot(np.arange(1,(args.end_iter)+1), all_accuracy, c=\"red\", label=\"Accuracy\") \n",
        "        Loss.append(100*(all_loss - np.min(all_loss))/np.ptp(all_loss))\n",
        "        Accuracies.append(all_accuracy)\n",
        "        Iters.append(args.end_iter)\n",
        "        Comps.append(comp1)\n",
        "        plt.title(f\"Loss Vs Accuracy Vs Iterations ({args.dataset},{args.arch_type})\") \n",
        "        plt.xlabel(\"Iterations\") \n",
        "        plt.ylabel(\"Loss and Accuracy\") \n",
        "        plt.legend() \n",
        "        plt.grid(color=\"gray\") \n",
        "        checkdir(f\"{os.getcwd()}/plots/lt/{args.arch_type}/{args.dataset}/\")\n",
        "        plt.savefig(f\"{os.getcwd()}/plots/lt/{args.arch_type}/{args.dataset}/{args.prune_type}_LossVsAccuracy_{comp1}.png\", dpi=1200) \n",
        "        plt.close()\n",
        "\n",
        "    ## Setting the variables back to 0 for the next iteration\n",
        "        best_accuracy = 0\n",
        "        all_loss = np.zeros(args.end_iter,float)\n",
        "        all_accuracy = np.zeros(args.end_iter,float)\n",
        "\n",
        "    ######################\n",
        "    ## Plotting \n",
        "    ######################\n",
        "    prune_iterations = np.arange(args.prune_iterations)                       ## Gives the range till number of prune_iterations\n",
        "    plt.plot(prune_iterations, bestacc, c=\"blue\", label=\"Winning tickets\")    ## Plotting the Best test accuracies at each prune iterations\n",
        "    plt.title(f\"Test Accuracy vs Unpruned Weights Percentage ({args.dataset},{args.arch_type})\") \n",
        "    plt.xlabel(\"Unpruned Weights Percentage\") \n",
        "    plt.ylabel(\"Test Accuracy\") \n",
        "    plt.xticks(prune_iterations, comp, rotation =\"vertical\") \n",
        "    plt.ylim(0,100)\n",
        "    plt.legend() \n",
        "    plt.grid(color=\"gray\") \n",
        "    checkdir(f\"{os.getcwd()}/plots/lt/{args.arch_type}/{args.dataset}/\")\n",
        "    plt.savefig(f\"{os.getcwd()}/plots/lt/{args.arch_type}/{args.dataset}/{args.prune_type}_AccuracyVsWeights.png\", dpi=1200) \n",
        "    plt.close() \n",
        "    return (model, prune_iterations, comp, bestacc)                   \n",
        "\n",
        "\n",
        "\n",
        "############################################################################\n",
        "# Function to make an empty mask of the same size as the model\n",
        "############################################################################\n",
        "def make_mask(model):\n",
        "    global step\n",
        "    global mask\n",
        "    step = 0\n",
        "    for name, param in model.named_parameters(): \n",
        "        if 'weight' in name:\n",
        "            step = step + 1\n",
        "    mask = [None]* step \n",
        "    step = 0\n",
        "    for name, param in model.named_parameters(): \n",
        "        if 'weight' in name:\n",
        "            tensor = param.data.cpu().numpy()\n",
        "            mask[step] = np.ones_like(tensor)\n",
        "            step = step + 1\n",
        "    step = 0\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    class data():\n",
        "        def __init__(self, lr=1.2e-3, batch_size=60, start_iter=0, end_iter=5, print_freq=2, valid_freq=1, resume=True, prune_type=\"lt\", gpu=\"0\", dataset=\"mnist\", arch_type=\"fc1\", prune_percent=50, prune_iterations=3):\n",
        "          self.lr=lr\n",
        "          self.batch_size=batch_size\n",
        "          self.start_iter=start_iter\n",
        "          self.end_iter=end_iter\n",
        "          self.print_freq=print_freq\n",
        "          self.valid_freq=valid_freq\n",
        "          self.resume=resume\n",
        "          self.prune_type=prune_type\n",
        "          self.gpu=gpu\n",
        "          self.dataset=dataset\n",
        "          self.arch_type=arch_type\n",
        "          self.prune_percent=prune_percent\n",
        "          self.prune_iterations=prune_iterations\n",
        "\n",
        "    args = data()\n",
        "\n",
        "\n",
        "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=args.gpu\n",
        "    \n",
        "    \n",
        "    #FIXME resample\n",
        "    resample = False\n",
        "\n",
        "    ##################################################################################\n",
        "    ## Creating empty lists to store the required entries in the __main__ function\n",
        "    ##################################################################################\n",
        "    Loss=[]\n",
        "    Accuracies=[]\n",
        "    Iters=[]\n",
        "    Comps=[]\n",
        "    \n",
        "    (model1, prune_iterations, comp, best_acc) = main(args, ITE=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "classifier.0.weight torch.Size([300, 784])\n",
            "classifier.0.bias torch.Size([300])\n",
            "classifier.2.weight torch.Size([100, 300])\n",
            "classifier.2.bias torch.Size([100])\n",
            "classifier.4.weight torch.Size([10, 100])\n",
            "classifier.4.bias torch.Size([10])\n",
            "\n",
            "\n",
            " \n",
            "--- Pruning Level [1:0/5]: ---\n",
            "classifier.0.weight  | nonzeros =  235200 /  235200 (100.00%) | total_pruned =       0 | shape = (300, 784)\n",
            "classifier.0.bias    | nonzeros =     300 /     300 (100.00%) | total_pruned =       0 | shape = (300,)\n",
            "classifier.2.weight  | nonzeros =   30000 /   30000 (100.00%) | total_pruned =       0 | shape = (100, 300)\n",
            "classifier.2.bias    | nonzeros =     100 /     100 (100.00%) | total_pruned =       0 | shape = (100,)\n",
            "classifier.4.weight  | nonzeros =    1000 /    1000 (100.00%) | total_pruned =       0 | shape = (10, 100)\n",
            "classifier.4.bias    | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)\n",
            "alive: 266610, pruned : 0, total: 266610, Compression rate :       1.00x  (  0.00% pruned)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Epoch: 0/10 Loss: 0.085251 Accuracy: 22.55% Best Accuracy: 22.55%:   0%|          | 0/10 [00:10<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 0/10 Loss: 0.085251 Accuracy: 22.55% Best Accuracy: 22.55%:  10%|â–ˆ         | 1/10 [00:10<01:31, 10.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 0/10 Loss: 0.085251 Accuracy: 22.55% Best Accuracy: 22.55%:  20%|â–ˆâ–ˆ        | 2/10 [00:20<01:20, 10.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 2/10 Loss: 0.154447 Accuracy: 97.12% Best Accuracy: 97.12%:  20%|â–ˆâ–ˆ        | 2/10 [00:30<01:20, 10.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 2/10 Loss: 0.154447 Accuracy: 97.12% Best Accuracy: 97.12%:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:30<01:11, 10.19s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 2/10 Loss: 0.154447 Accuracy: 97.12% Best Accuracy: 97.12%:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:57<01:30, 15.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 4/10 Loss: 0.059248 Accuracy: 97.66% Best Accuracy: 97.66%:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [01:41<01:30, 15.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 4/10 Loss: 0.059248 Accuracy: 97.66% Best Accuracy: 97.66%:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [02:33<02:08, 32.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 6/10 Loss: 0.003324 Accuracy: 98.11% Best Accuracy: 98.11%:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [03:30<02:08, 32.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 6/10 Loss: 0.003324 Accuracy: 98.11% Best Accuracy: 98.11%:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [03:30<01:58, 39.66s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 6/10 Loss: 0.003324 Accuracy: 98.11% Best Accuracy: 98.11%:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [04:32<01:32, 46.32s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 8/10 Loss: 0.007274 Accuracy: 98.05% Best Accuracy: 98.11%:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [05:38<01:32, 46.32s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 8/10 Loss: 0.007274 Accuracy: 98.05% Best Accuracy: 98.11%:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [05:38<00:52, 52.26s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 8/10 Loss: 0.007274 Accuracy: 98.05% Best Accuracy: 98.11%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [06:48<00:00, 40.81s/it]\n",
            "\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " \n",
            "--- Pruning Level [1:1/5]: ---\n",
            "classifier.0.weight  | nonzeros =  117600 /  235200 ( 50.00%) | total_pruned =  117600 | shape = (300, 784)\n",
            "classifier.0.bias    | nonzeros =     300 /     300 (100.00%) | total_pruned =       0 | shape = (300,)\n",
            "classifier.2.weight  | nonzeros =   15000 /   30000 ( 50.00%) | total_pruned =   15000 | shape = (100, 300)\n",
            "classifier.2.bias    | nonzeros =     100 /     100 (100.00%) | total_pruned =       0 | shape = (100,)\n",
            "classifier.4.weight  | nonzeros =     500 /    1000 ( 50.00%) | total_pruned =     500 | shape = (10, 100)\n",
            "classifier.4.bias    | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)\n",
            "alive: 133510, pruned : 133100, total: 266610, Compression rate :       2.00x  ( 49.92% pruned)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Epoch: 0/10 Loss: 0.050318 Accuracy: 0.76% Best Accuracy: 0.76%:   0%|          | 0/10 [00:11<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 0/10 Loss: 0.050318 Accuracy: 0.76% Best Accuracy: 0.76%:  10%|â–ˆ         | 1/10 [00:11<01:40, 11.21s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 0/10 Loss: 0.050318 Accuracy: 0.76% Best Accuracy: 0.76%:  20%|â–ˆâ–ˆ        | 2/10 [00:22<01:29, 11.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 2/10 Loss: 0.087222 Accuracy: 96.56% Best Accuracy: 96.56%:  20%|â–ˆâ–ˆ        | 2/10 [00:33<01:29, 11.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 2/10 Loss: 0.087222 Accuracy: 96.56% Best Accuracy: 96.56%:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:33<01:17, 11.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 2/10 Loss: 0.087222 Accuracy: 96.56% Best Accuracy: 96.56%:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:45<01:09, 11.55s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 4/10 Loss: 0.012545 Accuracy: 97.78% Best Accuracy: 97.84%:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [01:01<01:09, 11.55s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 4/10 Loss: 0.012545 Accuracy: 97.78% Best Accuracy: 97.84%:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:04, 12.87s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 4/10 Loss: 0.012545 Accuracy: 97.78% Best Accuracy: 97.84%:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:20<00:58, 14.52s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 6/10 Loss: 0.011530 Accuracy: 98.27% Best Accuracy: 98.27%:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:40<00:58, 14.52s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 6/10 Loss: 0.011530 Accuracy: 98.27% Best Accuracy: 98.27%:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:40<00:48, 16.33s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 6/10 Loss: 0.011530 Accuracy: 98.27% Best Accuracy: 98.27%:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [02:03<00:36, 18.20s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 8/10 Loss: 0.029431 Accuracy: 97.63% Best Accuracy: 98.27%:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [02:27<00:36, 18.20s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 8/10 Loss: 0.029431 Accuracy: 97.63% Best Accuracy: 98.27%:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [02:27<00:20, 20.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 8/10 Loss: 0.029431 Accuracy: 97.63% Best Accuracy: 98.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:54<00:00, 17.44s/it]\n",
            "\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " \n",
            "--- Pruning Level [1:2/5]: ---\n",
            "classifier.0.weight  | nonzeros =   58800 /  235200 ( 25.00%) | total_pruned =  176400 | shape = (300, 784)\n",
            "classifier.0.bias    | nonzeros =     300 /     300 (100.00%) | total_pruned =       0 | shape = (300,)\n",
            "classifier.2.weight  | nonzeros =    7500 /   30000 ( 25.00%) | total_pruned =   22500 | shape = (100, 300)\n",
            "classifier.2.bias    | nonzeros =     100 /     100 (100.00%) | total_pruned =       0 | shape = (100,)\n",
            "classifier.4.weight  | nonzeros =     250 /    1000 ( 25.00%) | total_pruned =     750 | shape = (10, 100)\n",
            "classifier.4.bias    | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)\n",
            "alive: 66960, pruned : 199650, total: 266610, Compression rate :       3.98x  ( 74.88% pruned)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Epoch: 0/10 Loss: 0.013246 Accuracy: 39.46% Best Accuracy: 39.46%:   0%|          | 0/10 [00:10<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 0/10 Loss: 0.013246 Accuracy: 39.46% Best Accuracy: 39.46%:  10%|â–ˆ         | 1/10 [00:10<01:37, 10.80s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 0/10 Loss: 0.013246 Accuracy: 39.46% Best Accuracy: 39.46%:  20%|â–ˆâ–ˆ        | 2/10 [00:21<01:26, 10.80s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 2/10 Loss: 0.007054 Accuracy: 97.61% Best Accuracy: 97.61%:  20%|â–ˆâ–ˆ        | 2/10 [00:32<01:26, 10.80s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 2/10 Loss: 0.007054 Accuracy: 97.61% Best Accuracy: 97.61%:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:32<01:16, 10.86s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 2/10 Loss: 0.007054 Accuracy: 97.61% Best Accuracy: 97.61%:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:44<01:06, 11.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 4/10 Loss: 0.106601 Accuracy: 97.39% Best Accuracy: 97.61%:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:55<01:06, 11.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 4/10 Loss: 0.106601 Accuracy: 97.39% Best Accuracy: 97.61%:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:55<00:56, 11.26s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 4/10 Loss: 0.106601 Accuracy: 97.39% Best Accuracy: 97.61%:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:08<00:46, 11.63s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 6/10 Loss: 0.009357 Accuracy: 98.23% Best Accuracy: 98.23%:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:21<00:46, 11.63s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 6/10 Loss: 0.009357 Accuracy: 98.23% Best Accuracy: 98.23%:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:21<00:36, 12.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 6/10 Loss: 0.009357 Accuracy: 98.23% Best Accuracy: 98.23%:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:35<00:25, 12.52s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 8/10 Loss: 0.003615 Accuracy: 97.98% Best Accuracy: 98.23%:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:49<00:25, 12.52s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 8/10 Loss: 0.003615 Accuracy: 97.98% Best Accuracy: 98.23%:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:49<00:13, 13.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 8/10 Loss: 0.003615 Accuracy: 97.98% Best Accuracy: 98.23%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.44s/it]\n",
            "\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " \n",
            "--- Pruning Level [1:3/5]: ---\n",
            "classifier.0.weight  | nonzeros =   29400 /  235200 ( 12.50%) | total_pruned =  205800 | shape = (300, 784)\n",
            "classifier.0.bias    | nonzeros =     300 /     300 (100.00%) | total_pruned =       0 | shape = (300,)\n",
            "classifier.2.weight  | nonzeros =    3750 /   30000 ( 12.50%) | total_pruned =   26250 | shape = (100, 300)\n",
            "classifier.2.bias    | nonzeros =     100 /     100 (100.00%) | total_pruned =       0 | shape = (100,)\n",
            "classifier.4.weight  | nonzeros =     125 /    1000 ( 12.50%) | total_pruned =     875 | shape = (10, 100)\n",
            "classifier.4.bias    | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)\n",
            "alive: 33685, pruned : 232925, total: 266610, Compression rate :       7.91x  ( 87.37% pruned)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Epoch: 0/10 Loss: 0.192878 Accuracy: 35.16% Best Accuracy: 35.16%:   0%|          | 0/10 [00:11<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 0/10 Loss: 0.192878 Accuracy: 35.16% Best Accuracy: 35.16%:  10%|â–ˆ         | 1/10 [00:11<01:39, 11.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 0/10 Loss: 0.192878 Accuracy: 35.16% Best Accuracy: 35.16%:  20%|â–ˆâ–ˆ        | 2/10 [00:21<01:28, 11.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 2/10 Loss: 0.001953 Accuracy: 97.92% Best Accuracy: 97.96%:  20%|â–ˆâ–ˆ        | 2/10 [00:33<01:28, 11.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 2/10 Loss: 0.001953 Accuracy: 97.92% Best Accuracy: 97.96%:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:33<01:18, 11.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 2/10 Loss: 0.001953 Accuracy: 97.92% Best Accuracy: 97.96%:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:46<01:10, 11.78s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 4/10 Loss: 0.026270 Accuracy: 98.15% Best Accuracy: 98.15%:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [01:00<01:10, 11.78s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 4/10 Loss: 0.026270 Accuracy: 98.15% Best Accuracy: 98.15%:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:01, 12.29s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 4/10 Loss: 0.026270 Accuracy: 98.15% Best Accuracy: 98.15%:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:50, 12.67s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 6/10 Loss: 0.010585 Accuracy: 97.84% Best Accuracy: 98.15%:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:27<00:50, 12.67s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 6/10 Loss: 0.010585 Accuracy: 97.84% Best Accuracy: 98.15%:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:27<00:39, 13.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 6/10 Loss: 0.010585 Accuracy: 97.84% Best Accuracy: 98.15%:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:41<00:26, 13.27s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 8/10 Loss: 0.002773 Accuracy: 97.96% Best Accuracy: 98.19%:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:55<00:26, 13.27s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 8/10 Loss: 0.002773 Accuracy: 97.96% Best Accuracy: 98.19%:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:55<00:13, 13.54s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 8/10 Loss: 0.002773 Accuracy: 97.96% Best Accuracy: 98.19%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:10<00:00, 13.02s/it]\n",
            "\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " \n",
            "--- Pruning Level [1:4/5]: ---\n",
            "classifier.0.weight  | nonzeros =   14700 /  235200 (  6.25%) | total_pruned =  220500 | shape = (300, 784)\n",
            "classifier.0.bias    | nonzeros =     300 /     300 (100.00%) | total_pruned =       0 | shape = (300,)\n",
            "classifier.2.weight  | nonzeros =    1875 /   30000 (  6.25%) | total_pruned =   28125 | shape = (100, 300)\n",
            "classifier.2.bias    | nonzeros =     100 /     100 (100.00%) | total_pruned =       0 | shape = (100,)\n",
            "classifier.4.weight  | nonzeros =      63 /    1000 (  6.30%) | total_pruned =     937 | shape = (10, 100)\n",
            "classifier.4.bias    | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)\n",
            "alive: 17048, pruned : 249562, total: 266610, Compression rate :      15.64x  ( 93.61% pruned)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Epoch: 0/10 Loss: 0.116824 Accuracy: 53.84% Best Accuracy: 53.84%:   0%|          | 0/10 [00:12<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 0/10 Loss: 0.116824 Accuracy: 53.84% Best Accuracy: 53.84%:  10%|â–ˆ         | 1/10 [00:12<01:48, 12.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 0/10 Loss: 0.116824 Accuracy: 53.84% Best Accuracy: 53.84%:  20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 2/10 Loss: 0.047032 Accuracy: 98.11% Best Accuracy: 98.11%:  20%|â–ˆâ–ˆ        | 2/10 [00:36<01:36, 12.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 2/10 Loss: 0.047032 Accuracy: 98.11% Best Accuracy: 98.11%:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 2/10 Loss: 0.047032 Accuracy: 98.11% Best Accuracy: 98.11%:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:14, 12.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 4/10 Loss: 0.013980 Accuracy: 98.17% Best Accuracy: 98.17%:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [01:03<01:14, 12.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 4/10 Loss: 0.013980 Accuracy: 98.17% Best Accuracy: 98.17%:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:03<01:04, 12.80s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 4/10 Loss: 0.013980 Accuracy: 98.17% Best Accuracy: 98.17%:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:16<00:52, 13.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 6/10 Loss: 0.001352 Accuracy: 98.25% Best Accuracy: 98.25%:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:30<00:52, 13.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 6/10 Loss: 0.001352 Accuracy: 98.25% Best Accuracy: 98.25%:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:30<00:39, 13.23s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 6/10 Loss: 0.001352 Accuracy: 98.25% Best Accuracy: 98.25%:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:44<00:26, 13.43s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 8/10 Loss: 0.010046 Accuracy: 98.23% Best Accuracy: 98.25%:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:58<00:26, 13.43s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 8/10 Loss: 0.010046 Accuracy: 98.23% Best Accuracy: 98.25%:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:58<00:13, 13.53s/it]\u001b[A\u001b[A\n",
            "\n",
            "Train Epoch: 8/10 Loss: 0.010046 Accuracy: 98.23% Best Accuracy: 98.25%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:11<00:00, 13.19s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EivHpSWTra4"
      },
      "source": [
        "#Loading the dataset for the classes 5-9\n",
        "We'll be testing the Lottery Ticket observed over the Classes 0-4 on this new data set having labels 5-9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qP8k4lBQ-CJ"
      },
      "source": [
        "    ##########################\n",
        "    ## Data Loader\n",
        "    ##########################\n",
        "transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "    ##########################################################################\n",
        "    ## Subsetting the MNIST data to select only Class 5 - 9 labels\n",
        "    ##########################################################################\n",
        "new_traindataset = datasets.MNIST('../data', train = True, download = True, transform = transform)\n",
        "new_testdataset = datasets.MNIST('../data', train=False, transform=transform)\n",
        "\n",
        "    ########################################################################\n",
        "    ## Extracting index for classes 5 - 9\n",
        "    ########################################################################\n",
        "idx = (new_traindataset.targets==5) | (new_traindataset.targets==6) | (new_traindataset.targets==7) | (new_traindataset.targets==8) | (new_traindataset.targets==9)\n",
        "idx2 = (new_testdataset.targets==5) | (new_testdataset.targets==6) | (new_testdataset.targets==7) | (new_testdataset.targets==8) | (new_testdataset.targets==9) \n",
        "\n",
        "    ########################################################################\n",
        "    ## Loading the train data corresponding to reqd classes\n",
        "    ########################################################################\n",
        "new_traindataset.targets = new_traindataset.targets[idx]\n",
        "new_traindataset.data = new_traindataset.data[idx]\n",
        "\n",
        "    ########################################################################\n",
        "    ## Loading the test data corresponding to reqd classes\n",
        "    ########################################################################\n",
        "new_testdataset.targets = new_testdataset.targets[idx2]\n",
        "new_testdataset.data = new_testdataset.data[idx2]\n",
        "\n",
        "\n",
        "new_train_loader = torch.utils.data.DataLoader(new_traindataset, batch_size = args.batch_size, shuffle = True, num_workers = 0, drop_last = False)\n",
        "new_test_loader = torch.utils.data.DataLoader(new_testdataset, batch_size = args.batch_size, shuffle = False, num_workers = 0, drop_last = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCCl_z9Pjn4M"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "ad53s2qXUl4I",
        "outputId": "0f3f5457-85ca-46ca-c9f5-1a39942457dc"
      },
      "source": [
        "pbar = tqdm(range(args.end_iter))\n",
        "all_loss = np.zeros(args.end_iter,float)\n",
        "all_accuracy = np.zeros(args.end_iter,float)\n",
        "\n",
        "###########################\n",
        "## Optimizer and Loss\n",
        "###########################\n",
        "optimizer = torch.optim.Adam(model1.parameters(), weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()         ## Default was F.nll_loss\n",
        " \n",
        "for iter_ in pbar:     ## Iterating over training iterations in each prune iteration\n",
        "    ################################\n",
        "    ## Frequency for Testing\n",
        "    ################################\n",
        "    accuracy = test(model1, new_test_loader, criterion)\n",
        "    \n",
        "    ###################\n",
        "    ## Training\n",
        "    ###################\n",
        "    loss = train(model1, new_train_loader, optimizer, criterion)\n",
        "    all_loss[iter_] = loss\n",
        "    all_accuracy[iter_] = accuracy\n",
        "    # print(f\"\\nTrain epoch: {iter_} | All_accuracy: {all_accuracy} |  accuracy at that epoch: {accuracy}\")\n",
        "    # print(f\"\\nTrain epoch: {iter_} | All_loss: {all_loss} | accuracy at that epoch: {loss}\")\n",
        "\n",
        "plt.plot(all_loss, color = 'blue', label = \"Loss\")\n",
        "plt.plot(all_accuracy, color = 'red', label = \"Accuracy\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|â–ˆ         | 1/10 [00:12<01:50, 12.29s/it]\u001b[A\u001b[A\n",
            "\n",
            " 20%|â–ˆâ–ˆ        | 2/10 [00:23<01:36, 12.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:35<01:23, 11.95s/it]\u001b[A\u001b[A\n",
            "\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:47<01:11, 11.91s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:59<00:59, 11.87s/it]\u001b[A\u001b[A\n",
            "\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:10<00:47, 11.79s/it]\u001b[A\u001b[A\n",
            "\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:22<00:35, 11.73s/it]\u001b[A\u001b[A\n",
            "\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:33<00:23, 11.70s/it]\u001b[A\u001b[A\n",
            "\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:45<00:11, 11.64s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:56<00:00, 11.70s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f2c370bfdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "4ftKY7yaw5au",
        "outputId": "3f76ff24-26c8-460f-b712-e8adf1bc28f3"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set()\n",
        "plt.plot(all_loss, color = 'blue', label = \"Loss\")\n",
        "plt.plot(all_accuracy, color = 'red', label = \"Accuracy\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Prune Iteration\")\n",
        "plt.ylabel(\"Accuracy/ Loss\")\n",
        "plt.title(\"Plot of Accuracy and Loss vs. Pruning Iterations\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Plot of Accuracy and Loss vs. Pruning Iterations')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCxVQjxty5Dd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}